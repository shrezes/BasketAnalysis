{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrlcxB2Xjbry/Pz6OFewqu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrezes/BasketAnalysis/blob/main/BasketAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlCMBqt9bPqt",
        "outputId": "04490e44-b903-451f-d518-853fb9828e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load the dataset\n",
        "def load_data(filepath):\n",
        "    transactions = []\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            transaction = line.strip().split()\n",
        "            transactions.append(transaction)\n",
        "    return transactions\n",
        "\n",
        "# Upload 'Sales1998.txt' to Colab first.\n",
        "transactions = load_data('Sales1998.txt')\n",
        "\n",
        "# Create a one-hot encoded dataframe\n",
        "def create_one_hot(transactions):\n",
        "    unique_items = set(item for sublist in transactions for item in sublist)\n",
        "    one_hot = []\n",
        "    for transaction in transactions:\n",
        "        row = [1 if item in transaction else 0 for item in unique_items]\n",
        "        one_hot.append(row)\n",
        "    df = pd.DataFrame(one_hot, columns=list(unique_items), dtype=bool) # Added dtype=bool\n",
        "    return df\n",
        "\n",
        "df = create_one_hot(transactions)\n",
        "\n",
        "# Apply the Apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(df, min_support=0.004, use_colnames=True)\n",
        "\n",
        "# Check if frequent itemsets is empty\n",
        "if frequent_itemsets.empty:\n",
        "    print(\"No frequent itemsets found. Try lowering the 'min_support' value.\")\n",
        "else:\n",
        "    # Generate association rules\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
        "\n",
        "    # Display the results\n",
        "    print(\"Frequent Itemsets:\")\n",
        "    print(frequent_itemsets)\n",
        "\n",
        "    print(\"\\nAssociation Rules:\")\n",
        "    print(rules)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saqYL0_Bb_2J",
        "outputId": "3b0eb8c0-c90c-4595-f450-8678d5629e4f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "    support itemsets\n",
            "0  0.004021    (319)\n",
            "1  0.004050    (846)\n",
            "2  0.004050    (865)\n",
            "3  0.004109   (1352)\n",
            "4  0.004021   (1297)\n",
            "5  0.004197    (277)\n",
            "6  0.004021    (827)\n",
            "\n",
            "Association Rules:\n",
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, representativity, leverage, conviction, zhangs_metric, jaccard, certainty, kulczynski]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load the dataset\n",
        "def load_data(filepath):\n",
        "    transactions = []\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            transaction = line.strip().split()\n",
        "            transactions.append(transaction)\n",
        "    return transactions\n",
        "\n",
        "# Load the product list\n",
        "def load_product_names(filepath):\n",
        "    product_names = {}\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split(' ', 1)\n",
        "            if len(parts) == 2:\n",
        "                product_id, product_name = parts\n",
        "                product_names[product_id] = product_name\n",
        "    return product_names\n",
        "\n",
        "# Upload 'Sales1998.txt' and 'productList.txt' to Colab first.\n",
        "transactions = load_data('Sales1998.txt')\n",
        "product_names = load_product_names('productList.txt')\n",
        "\n",
        "# Create a one-hot encoded dataframe\n",
        "def create_one_hot(transactions, product_names):\n",
        "    unique_items = set()\n",
        "    for transaction in transactions:\n",
        "        for item_id in transaction:\n",
        "            if item_id in product_names:\n",
        "                unique_items.add(product_names[item_id])\n",
        "    one_hot = []\n",
        "    for transaction in transactions:\n",
        "        row = [product_names[item_id] if item_id in transaction and item_id in product_names else None for item_id in transaction]\n",
        "        # Filter out None values to avoid errors and keep only valid products\n",
        "        row = [item for item in row if item]\n",
        "\n",
        "        # Create a boolean row, with True if the unique item is in the transaction, False otherwise\n",
        "        bool_row = [True if unique_item in row else False for unique_item in unique_items]\n",
        "        one_hot.append(bool_row)\n",
        "    df = pd.DataFrame(one_hot, columns=list(unique_items), dtype=bool) # Added dtype=bool\n",
        "    return df\n",
        "\n",
        "df = create_one_hot(transactions, product_names)\n",
        "\n",
        "# Apply the Apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(df, min_support=0.004, use_colnames=True)\n",
        "\n",
        "# Check if frequent itemsets is empty\n",
        "if frequent_itemsets.empty:\n",
        "    print(\"No frequent itemsets found. Try lowering the 'min_support' value.\")\n",
        "else:\n",
        "    # Generate association rules\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
        "\n",
        "    # Function to convert itemset numbers to names\n",
        "    def get_product_names_from_itemset(itemset, product_names):\n",
        "        return [item for item in itemset]\n",
        "\n",
        "    # Convert itemset numbers to names in frequent itemsets\n",
        "    frequent_itemsets['itemsets_names'] = frequent_itemsets['itemsets'].apply(lambda x: get_product_names_from_itemset(x, product_names))\n",
        "\n",
        "    # Convert itemset numbers to names in rules\n",
        "    rules['antecedents_names'] = rules['antecedents'].apply(lambda x: get_product_names_from_itemset(x, product_names))\n",
        "    rules['consequents_names'] = rules['consequents'].apply(lambda x: get_product_names_from_itemset(x, product_names))\n",
        "\n",
        "    # Display the results\n",
        "    print(\"Frequent Itemsets:\")\n",
        "    print(frequent_itemsets[['support', 'itemsets_names']]) # Display support and item names\n",
        "\n",
        "    print(\"\\nAssociation Rules:\")\n",
        "    print(rules[['antecedents_names', 'consequents_names', 'support', 'confidence', 'lift']]) # Display product names in rules\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww2V2oijf6lc",
        "outputId": "7390ad6a-510a-4198-879b-68a6f903a56d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "    support                itemsets_names\n",
            "0  0.004021          [\"Ebony Mixed Nuts\"]\n",
            "1  0.004050  [\"Nationeel Fudge Brownies\"]\n",
            "2  0.004021      [\"Booker String Cheese\"]\n",
            "3  0.004197     [\"Great English Muffins\"]\n",
            "4  0.004109      [\"Carrington Ice Cream\"]\n",
            "5  0.004021    [\"Excellent Orange Juice\"]\n",
            "6  0.004050    [\"Nationeel Dried Apples\"]\n",
            "\n",
            "Association Rules:\n",
            "Empty DataFrame\n",
            "Columns: [antecedents_names, consequents_names, support, confidence, lift]\n",
            "Index: []\n"
          ]
        }
      ]
    }
  ]
}